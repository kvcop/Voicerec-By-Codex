# Live Diarization Service Testing Plan

## Step 1: Set Up a Staging Environment for Diarization

- **Mirror Production Setup:** Prepare a staging environment that closely matches production. Ensure the **speaker diarization gRPC service** is deployable in this environment (e.g. container or VM) and listening on the expected port (e.g. 50052 as per design)[\[1\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md#L2-L5).
- **Install Dependencies:** Install all necessary ML frameworks and diarization libraries (e.g. PyTorch, NVIDIA NeMo toolkit with ASR support, OmegaConf)[\[2\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarization_resources.py#L94-L102). If no GPU is available, configure the environment for CPU execution (e.g. set GPU_CUDA_VARIANT=cpu to install CPU versions of PyTorch[\[3\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/docs/researches/2025-09-27-v1-gpu-audio-processing.md#L2-L5)). Use a smaller model or shorten audio input in CPU mode to keep processing time reasonable[\[1\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md#L2-L5).
- **Acquire Model Artifacts:** Ensure the **pre-trained diarization models and config** (VAD model, speaker embedding model, MSDD model, and YAML config) are present on disk in the expected paths. Auto-download is not implemented, so manually download these NeMo checkpoint files and place them in gpu_services/models/ (or set environment variables like DIARIZATION_MODEL_ROOT to their location)[\[4\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarization_resources.py#L120-L128). Verify that the diarization service can locate and load the config and model files on startup without errors.

## Step 2: Implement Automated Test Coverage

- **Unit Tests for Logic:** Write unit tests for critical components of the diarization service. For example, test the file path resolution and validation logic (ensuring non-existent files produce the correct gRPC error), test fallback behavior when no segments are returned, and test the segment normalization (e.g. that speakers are labeled "Speaker 1", "Speaker 2", etc.). The code already includes a fallback that returns a single full-span segment labeled "Speaker 1" if no segments were detected[\[5\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L213-L219) - verify this in a unit test by simulating an empty diarization result.
- **Mocked Interface Tests:** If the service provides a client interface or mock clients, use those in tests. For instance, the project's test suite uses a MockDiarizeClient with a fixture JSON to simulate diarization results[\[6\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/backend/tests/test_grpc_client.py#L32-L40). Integrate similar fixtures to validate that the application correctly consumes diarization outputs (e.g. ensure that a meeting processing pipeline can handle a DiarizationResult with multiple segments).
- **Integration Test with Sample Audio:** Conduct an integration test against the running diarization gRPC service in the staging environment. Start the diarization service (using the same gRPC server startup as production) and send it a known audio sample via gRPC. Use a short **multi-speaker audio clip (~30 seconds)** with at least 2 speakers for this test[\[1\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md#L2-L5). You can download a public sample (via wget in the staging environment) that contains dialogue to simulate a meeting or conversation. Also test with a **single-speaker audio** clip to ensure the service handles that scenario (it should return one speaker covering the full duration, either via the model or via fallback)[\[1\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md#L2-L5).
- **Expected Outcome Verification:** For the multi-speaker test audio, verify that the DiarizationResult contains multiple segments with different speaker labels (e.g. "Speaker 1" and "Speaker 2") and that their time stamps align with the speech in the audio[\[1\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md#L2-L5). For the single-speaker audio, expect either one segment spanning the entire audio or the service's single-speaker fallback to kick in if voice activity detection fails[\[5\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L213-L219). If possible, prepare a "ground truth" reference for the test audio (manual annotation of who speaks when) to compare against the service output for accuracy. While full DER (Diarization Error Rate) calculation may not be automated in staging, even a manual check or simplified assertion (e.g. at least 2 distinct speakers detected in the multi-speaker file) can increase confidence.

## Step 3: Add Telemetry and Monitoring Checkpoints

- **Logging Key Events:** Enable detailed logging in the diarization service for visibility during testing and production. The service should log when a request is received and when processing finishes, including how many speaker segments were produced and how long it took[\[7\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L220-L228). Ensure these logs are visible in the staging environment. For example, upon completion the service logs: _"Finished diarization for \[file\] with X segments in Y seconds."_[\[7\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L220-L228). This helps track performance and whether the number of segments seems reasonable for the input.
- **Metric Collection:** Identify critical metrics to monitor. This can include **processing latency** (time per audio minute), **CPU/GPU utilization**, and **number of speakers detected per audio**. Instrument the code to record these metrics at telemetry checkpoints - e.g. increment a counter for "diarization requests processed", log the duration measured for each request (already in logs) and perhaps emit a metric for "speakers_detected_count". Monitoring the speakers count can catch anomalies (e.g. if typically 2-3 speakers are expected but the service consistently returns 1, it may indicate a failure in diarization).
- **Error and Exception Tracking:** Ensure any errors in the pipeline are captured. The service should already abort on missing dependencies or resources with clear error messages[\[2\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarization_resources.py#L94-L102)[\[4\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarization_resources.py#L120-L128). Use staging to verify that such failures (e.g. missing model file or an unexpected runtime exception) are logged and/or reported to your monitoring system. This will allow quick diagnosis if something goes wrong after deployment.
- **Dry-Run in Shadow Mode:** As a telemetry-focused test, consider running the diarization service in **shadow mode** alongside production traffic (if feasible). In staging, simulate this by feeding real meeting audio recordings through the diarization service _without_ exposing its results to end-users. Log the outputs and timing. This exercise can reveal performance bottlenecks and ensure that telemetry hooks (logging and metrics) are working end-to-end before full rollout.

## Step 4: Plan Risk Mitigation and Production Rollout

- **Feature Flag & Gradual Rollout:** Protect the diarization feature behind a feature flag or configuration toggle. Initially deploy the diarization service in production but keep it disabled or used only for a small percentage of cases. For example, route only internal or a subset of user requests to the diarization pipeline while others continue with a single-speaker assumption. This allows monitoring the service's behavior under real conditions with minimal user impact. Gradually increase traffic to the diarization service as confidence grows.
- **Fallback Strategy:** Maintain a robust fallback in case of failures or poor performance. The system already has a built-in fallback to treat the entire audio as one speaker if the diarization returns no segments[\[5\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L213-L219). Extend this concept to production readiness: if the diarization service fails (timeout or error), ensure the overall meeting processing pipeline still proceeds (perhaps labeling all speech as a single speaker rather than failing outright). This way, a diarization outage does not block the core transcription functionality.
- **Staging Verification before Launch:** Before enabling diarization for end users, replicate a full meeting processing flow in staging. For example, run a full meeting audio through ASR -> Diarization -> downstream components (e.g. assign speaker labels to transcript, then summarization). Verify end-to-end that transcripts are correctly annotated with speakers and nothing breaks in formatting or storage. This staging "dress rehearsal" should use realistic data and run under production-like resource constraints. Confirm that performance is acceptable (e.g. processing a 1-hour meeting does not exceed time/memory limits). Document any deviations or slow points and address them (such as by splitting audio or optimizing configurations) prior to rollout.
- **Monitoring and Alerting in Production:** Once enabled, closely monitor the diarization service in production. Use the telemetry from Step 3 to set up alerts (e.g. if diarization latency spikes or error rates increase). Also monitor qualitative feedback - e.g. have internal staff review a few diarized transcripts for correctness. Be prepared to quickly disable the diarization (via the feature flag) if any severe issues arise (such as incorrect attributions or crashes).
- **Post-Rollout Review:** Finally, plan a post-rollout evaluation. Gather metrics like how often diarization is producing multiple speakers vs. single speaker, and check if the diarization improves overall user experience. This review will inform if further tuning or model improvements are needed. By following this cautious rollout with ample testing, logging, and fallback provisions, the team can mitigate risks and enable the live diarization service reliably for all users[\[1\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md#L2-L5)[\[5\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L213-L219).

[\[1\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md#L2-L5) TODO_GPU.md

<https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/TODO_GPU.md>

[\[2\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarization_resources.py#L94-L102) [\[4\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarization_resources.py#L120-L128) diarization_resources.py

<https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarization_resources.py>

[\[3\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/docs/researches/2025-09-27-v1-gpu-audio-processing.md#L2-L5) 2025-09-27-v1-gpu-audio-processing.md

<https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/docs/researches/2025-09-27-v1-gpu-audio-processing.md>

[\[5\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L213-L219) [\[7\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py#L220-L228) diarize_service.py

<https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/gpu_services/diarize_service.py>

[\[6\]](https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/backend/tests/test_grpc_client.py#L32-L40) test_grpc_client.py

<https://github.com/kvcop/Voicerec-By-Codex/blob/f8cd28ff17959864b82142b97c93d7f0c8967c5d/backend/tests/test_grpc_client.py>
